<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<!-- saved from url=(0023)https://jonbarron.info/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="“width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="https://jonbarron.info/seal_icon.png">
  <title>Qingnan Fan (樊庆楠)</title>
  
  <link href="./QingnanFan_files/css" rel="stylesheet" type="text/css">
  <script charset="utf-8" src="chrome-extension://jgphnjokjhjlcnnajmfjlacjnjkhleah/js/btype.js"></script></head>

  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tbody><tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
        <td width="100%" valign="middle">
        <p align="center">
          <name>Qingnan Fan (樊庆楠)</name>
        </p>
        <p>
          I am a Senior Researcher in the Visual Computing Center of Tencent AI Lab. If you are interested in the internship about 3DV in our group, feel free to drop me an email</a>.
        </p>
        <p>
          I was a post-doctoral researcher in Stanford University supervised by <a
              href="https://geometry.stanford.edu/member/guibas/"> Prof. Leonidas Guibas</a> between 2019 to 2021.
        </p>
        <p> I obtained my PhD degree in the  <a
                href="http://www.cs.sdu.edu.cn/">Computer Science and Technology School</a> of <a
                href="http://www.sdu.edu.cn/">Shandong University</a> at 2019. I was supervised by <a
                href="http://www.cs.sdu.edu.cn/~baoquan/"> Prof. Baoquan Chen</a>.
        </p>

        <!-- <p>
            I was a research intern in the Visual Computing Group of MSRA supervised by <a href="http://www.davidwipf.com/">David Wipf</a> from Sept. 2016 to Feb. 2018. I also collaborated with <a href="https://www.microsoft.com/en-us/research/people/xtong/">Xin Tong</a>, <a href="https://www.microsoft.com/en-us/research/people/ganghua/">Gang Hua</a> and <a href="http://jlyang.org/">Jiaolong Yang</a> while in MSR.
        </p>
        <p>
            I was also a research intern in the Advanced Innovation Center for Future Visual Entertainment led by <a
                href="http://www.cs.sdu.edu.cn/~baoquan/"> Prof. Baoquan Chen</a>, in Beijing Film Academy between Mar. 2018 and Aug. 2019.
        </p>
        <p>
          I visited Tel Aviv University, Hebrew University of Jerusalem several times between 2014 to 2015 to work with 
              <a href="http://www.math.tau.ac.il/~dcor/">Prof. Daniel Cohen-Or</a> and 
              <a href="http://www.cs.huji.ac.il/~danix/">Prof. Dani Lischinski</a>.
        </p> -->
        <p align="center">
          <a href="mailto:fqnchina@gmail.com">Email</a> &nbsp/&nbsp
          <a href="./QingnanFan_files/qingnan_cv.pdf">CV</a> &nbsp/&nbsp
          <a href="./QingnanFan_files/Qingnan-bio.txt">Biography</a> &nbsp/&nbsp
          <a href="https://scholar.google.co.uk/citations?user=2cY2zwUAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
          <a href="https://www.linkedin.com/in/qingnan-fan-02140aa7/">LinkedIn</a> &nbsp/&nbsp
          <a href="https://twitter.com/FanQingnan/">Twitter</a> &nbsp/&nbsp
          <a href="https://github.com/fqnchina/">Github</a>
        </p>
        </td>
        <td width="33%">
        <img src="./QingnanFan_files//qingnan_circle_v3.jpg" width="250" alt="" style="border-style: none" align="middle">
        </td>
      </tr>
      </tbody></table>

      
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
        <td width="100%" valign="middle">
          <heading>Publications</heading>
        </td>
      </tr>
      </tbody></table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

          <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
            <td width="25%">
              <div class="one">
              <div class="two" id="portrait_image" style="opacity: 0;">
              <img src="./QingnanFan_files//vat_mart.gif" width="175" alt="" style="border-style: none" align="middle">
              </div>
              <img src="./QingnanFan_files//vat_mart.gif" width="175" alt="" style="border-style: none" align="middle">
              </div>
              <script type="text/javascript">
              function portrait_start() {
              document.getElementById('portrait_image').style.opacity = "1";
              }
              function portrait_stop() {
              document.getElementById('portrait_image').style.opacity = "0";
              }
              portrait_stop()
              </script>
            </td>
            <td valign="top" width="75%">
          <a href="./QingnanFan_files/iclr_2022.pdf">
                  <papertitle>VAT-Mart: Learning Visual Action Trajectory Proposals for Manipulating 3D ARTiculated Objects</papertitle>
          </a>
          <br>     
          <a href="https://warshallrho.github.io/" target="_blank">Ruihai Wu*</a>,
          <a href="https://www.researchgate.net/profile/Yan-Zhao-182" target="_blank">Yan Zhao*</a>,
          <a href="https://cs.stanford.edu/~kaichun/">Kaichun Mo*</a>, 
          <a href="https://guozz.cn/" target='_blank'>Zizheng Guo</a>,
          <a href="https://github.com/galaxy-qazzz" target='_blank'>Yian Wang</a>,
          <a href="https://tianhaowuhz.github.io/" target="_blank">Tianhao Wu</a>,
          <strong>Qingnan Fan</strong>, 
          <a href="https://xuelin-chen.github.io/" target='_blank'>Xuelin Chen</a>,
          <a href="http://geometry.stanford.edu/member/guibas/index.html" target="_blank">Leonidas Guibas</a>,
          <a href="https://zsdonghao.github.io/" target='_blank'>Hao Dong</a>.
          <br>
              <em>ICLR</em>, 2022</strong><br>
              <a href="https://arxiv.org/abs/2106.14440" target="_blank">arXiv</a>
              /
              <a href="https://hyperplane-lab.github.io/vat-mart" target="_blank">project page</a>
              /
              <a href="https://www.youtube.com/watch?v=HjhsLKf1eQY" target="_blank">video</a>
              /
              <a href="./QingnanFan_files/iclr-2022.bib">bibtex</a>
              <p></p>
              <p> We design an interaction-for-perception framework, VAT-MART, to learn actionable visual representations for more effective manipulation of 3D articulated objects.</p>
            </td>
          </tr>

          <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
            <td width="25%">
              <div class="one">
              <div class="two" id="portrait_image" style="opacity: 0;">
              <img src="./QingnanFan_files/iccv_2021_captra4.gif" width="175" alt="" style="border-style: none" align="middle">
              </div>
              <img src="./QingnanFan_files/iccv_2021_captra4.gif" width="175" alt="" style="border-style: none" align="middle">
              </div>
              <script type="text/javascript">
              function portrait_start() {
              document.getElementById('portrait_image').style.opacity = "1";
              }
              function portrait_stop() {
              document.getElementById('portrait_image').style.opacity = "0";
              }
              portrait_stop()
              </script>
            </td>
            <td valign="top" width="75%">
          <a href="./QingnanFan_files/iccv_2021_captra.pdf">
                  <papertitle>CAPTRA: CAtegory-level Pose Tracking for Rigid and Articulated Objects from Point Clouds</papertitle>
          </a>
          <br>          
          Yijia Weng*, 
          <a href="https://hughw19.github.io/">He Wang*</a>, 
          Qiang Zhou,
          <a href="https://yzqin.github.io/">Yuzhe Qin</a>, 
          <a href="https://geometry.stanford.edu/person.php?id=duanyq19">Yueqi Duan</a>, 
          <strong>Qingnan Fan</strong>, 
          <a href="https://cfcs.pku.edu.cn/baoquan/">Baoquan Chen</a>,
          <a href="http://ai.ucsd.edu/~haosu/">Hao Su</a>,
          <a href="https://geometry.stanford.edu/member/guibas/index.html">Leonidas Guibas</a>.
          <br>
              <em>ICCV</em>, 2021 <strong style="color:red">(Oral)</strong><br>
              <a href="https://arxiv.org/abs/2104.03437">arXiv</a>
              /
              <a href="https://github.com/HalfSummer11/CAPTRA">codes</a>
              /
              <a href="https://www.youtube.com/watch?v=JFPcOHCH2O0">video</a>
              /
              <a href="./QingnanFan_files/iccv_2021_captra.bib">bibtex</a>
              <p></p>
              <p> For the first time, we propose a unified framework that can handle 9-DoF pose tracking for novel rigid object instances as well as per-part pose tracking for 3D articulated objects.</p>
            </td>
          </tr>

          <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
            <td width="25%">
              <div class="one">
              <div class="two" id="portrait_image" style="opacity: 0;">
              <img src="./QingnanFan_files/iccv_2021_tupleinfoNCE_large.png" width="175" alt="" style="border-style: none" align="middle">
              </div>
              <img src="./QingnanFan_files/iccv_2021_tupleinfoNCE_large.png" width="175" alt="" style="border-style: none" align="middle">
              </div>
              <script type="text/javascript">
              function portrait_start() {
              document.getElementById('portrait_image').style.opacity = "1";
              }
              function portrait_stop() {
              document.getElementById('portrait_image').style.opacity = "0";
              }
              portrait_stop()
              </script>
            </td>
            <td valign="top" width="75%">
          <a href="./QingnanFan_files/iccv_2021_tupleinfoNCE.pdf">
                  <papertitle>Contrastive Multimodal Fusion with TupleInfoNCE</papertitle>
          </a>
          <br>          
          Yunze Liu,
          <strong>Qingnan Fan</strong>, 
          <a href="https://scholar.google.com/citations?user=voqw10cAAAAJ&hl=en">Shanghang Zhang</a>, 
          <a href="https://zsdonghao.github.io/">Hao Dong</a>,
          <a href="https://www.cs.princeton.edu/~funk/">Thomas Funkhouser</a>,
          <a href="https://ericyi.github.io/">Li Yi</a>.
          <br>
              <em>ICCV</em>, 2021</strong><br>
              <a href="https://arxiv.org/abs/2107.02575">arXiv</a>
              /
              <a href="./QingnanFan_files/iccv_2021_tupleinfoNCE.bib">bibtex</a>
              <p></p>
              <p> We propose a novel contrastive learning objective, TupleInfoNCE. It contrasts tuples based not only on positive and negative correspondences, but also by composing new negative tuples using modalities describing different scenes.</p>
            </td>
          </tr>

          <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
            <td width="25%">
              <div class="one">
              <div class="two" id="portrait_image" style="opacity: 0;">
              <img src="./QingnanFan_files/cvpr21_localization_thumbnail.png" width="175" alt="" style="border-style: none" align="middle">
              </div>
              <img src="./QingnanFan_files/cvpr21_localization_thumbnail.png" width="175" alt="" style="border-style: none" align="middle">
              </div>
              <script type="text/javascript">
              function portrait_start() {
              document.getElementById('portrait_image').style.opacity = "1";
              }
              function portrait_stop() {
              document.getElementById('portrait_image').style.opacity = "0";
              }
              portrait_stop()
              </script>
            </td>
            <td valign="top" width="75%">
          <a href="./QingnanFan_files/cvpr_2021_localization.pdf">
                  <papertitle>Robust Neural Routing Through Space Partitions for Camera Relocalization in Dynamic Indoor Environments</papertitle>
          </a>
          <br>          
          <a href="https://scholar.google.com/citations?user=vtZMhssAAAAJ&hl=en/">Siyan Dong*</a>, 
          <strong>Qingnan Fan*</strong>, 
          <a href="https://ai.stanford.edu/~hewang/">He Wang</a>, 
          Ji Shi,
          <a href="https://ericyi.github.io/">Li Yi</a>, 
          <a href="https://www.cs.princeton.edu/~funk/">Thomas Funkhouser</a>,
          <a href="https://cfcs.pku.edu.cn/baoquan/">Baoquan Chen</a>,
          <a href="https://geometry.stanford.edu/member/guibas/index.html">Leonidas Guibas</a>.
          <br>
              <em>CVPR</em>, 2021 <strong style="color:red">(Oral)</strong><br>
              <a href="https://arxiv.org/abs/2012.04746">arXiv</a>
              /
              <a href="https://github.com/siyandong/NeuralRouting">codes</a>
              /
              <a href="https://www.youtube.com/watch?v=_1eInWKbuVA" target="_blank">video</a>
              /
              <a href="./QingnanFan_files/cvpr_2021_localization.bib">bibtex</a>
              <p></p>
              <p> A novel outlier-aware neural tree to tackle the camera localization challenges in dynamic indoor environments. It achieves the best performance in the RIO-10 benchmark.</p>
            </td>
          </tr>

              <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
                <td width="25%">
                  <div class="one">
                  <div class="two" id="portrait_image" style="opacity: 0;">
                  <img src="./QingnanFan_files/cvpr21_manga_thumbnailv2.png" width="175" alt="" style="border-style: none" align="middle">
                  </div>
                  <img src="./QingnanFan_files/cvpr21_manga_thumbnailv2.png" width="175" alt="" style="border-style: none" align="middle">
                  </div>
                  <script type="text/javascript">
                  function portrait_start() {
                  document.getElementById('portrait_image').style.opacity = "1";
                  }
                  function portrait_stop() {
                  document.getElementById('portrait_image').style.opacity = "0";
                  }
                  portrait_stop()
                  </script>
                </td>
                <td valign="top" width="75%">
              <a href="https://www.dropbox.com/s/33mbcwfv3e4n1v7/cvpr21_manga.pdf?dl=0">
                      <papertitle>Generating Manga from Illustrations via Mimicking Manga Creation Workflow</papertitle>
              </a>
              <br>          
              <a href="https://github.com/lllyasviel">Lvmin Zhang</a>, 
              <a href="https://github.com/SystemErrorWang">Xinrui Wang</a>, 
              <strong>Qingnan Fan</strong>, 
              Yi Ji, 
              ChunPing Liu.
              <br>
                  <em>CVPR</em>, 2021<br>
                  <a href="https://lllyasviel.github.io/MangaFilter/">project page</a>
                  / 
                  <a href="./QingnanFan_files/cvpr_2021_manga.bib">bibtex</a>
                  <p></p>
                  <p> A data-driven framework to convert a digital illustration into three corresponding components: manga line drawing, regular screentone, and irregular screen texture. These components can be directly composed into manga images and can be further retouched for more plentiful manga creations.</p>
                </td>
              </tr>

                <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
                  <td width="25%">
                    <div class="one">
                    <div class="two" id="portrait_image" style="opacity: 0;">
                    <img src="./QingnanFan_files/tpami21_thumbnail.gif" width="175" alt="" style="border-style: none" align="middle">
                    </div>
                    <img src="./QingnanFan_files/tpami21_thumbnail.gif" width="175" alt="" style="border-style: none" align="middle">
                    </div>
                    <script type="text/javascript">
                    function portrait_start() {
                    document.getElementById('portrait_image').style.opacity = "1";
                    }
                    function portrait_stop() {
                    document.getElementById('portrait_image').style.opacity = "0";
                    }
                    portrait_stop()
                    </script>
                  </td>
                  <td valign="top" width="75%">
                <a href="./QingnanFan_files/tpami_2021.pdf">
                        <papertitle>A General Decoupled Learning Framework for Parameterized Image Operators</papertitle>
                </a>
                <br>
                <strong>Qingnan Fan*</strong>, 
                <a href="http://www.dongdongchen.bid/">Dongdong Chen*</a>, 
                <a href="http://www.lyuan.org/">Lu Yuan</a>,
                <a href="https://www.microsoft.com/en-us/research/people/ganghua/">Gang Hua</a>, 
                <a href="http://staff.ustc.edu.cn/~ynh/">Nenghai Yu</a>, 
                <a href="http://www.cs.sdu.edu.cn/~baoquan/">Baoquan Chen</a>.
                <br>
                    <em>TPAMI</em>, 2021 <br>
                    <a href="https://arxiv.org/abs/1907.05852">arXiv</a>
                    / 
                    <a href="https://github.com/fqnchina/DecoupleLearning">codes</a>
                    /
                    <!-- <a href="./QingnanFan_files/tpami21_video-presentation.mp4">demo</a>
                    / -->
                    <a href="./QingnanFan_files/tpami_2021.bib">bibtex</a>
                    <p></p>
                    <p> A journal extension of our ECCV 2018 paper. We further propose a cheap parameter-tuning version of the decouple learning framework that enables real-time alternation between different image operators. </p>
                  </td>
                </tr>

        <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
          <td width="25%">
            <div class="one">
            <div class="two" id="portrait_image" style="opacity: 0;">
            <img src="./QingnanFan_files/arxiv20_assembly_thumbnailv2.png" width="175" alt="" style="border-style: none" align="middle">
            </div>
            <img src="./QingnanFan_files/arxiv20_assembly_thumbnailv2.png" width="175" alt="" style="border-style: none" align="middle">
            </div>
            <script type="text/javascript">
            function portrait_start() {
            document.getElementById('portrait_image').style.opacity = "1";
            }
            function portrait_stop() {
            document.getElementById('portrait_image').style.opacity = "0";
            }
            portrait_stop()
            </script>
          </td>
          <td valign="top" width="75%">
        <a href="./QingnanFan_files/arxiv_2020_part_assembly.pdf">
                <papertitle>Generative 3D Part Assembly via Dynamic Graph Learning</papertitle>
        </a>
        <br>
        Jialei Huang*,
        <a href="https://championchess.github.io/">Guanqi Zhan*</a>, 
        <strong>Qingnan Fan</strong>, 
        <a href="https://cs.stanford.edu/~kaichun/">Kaichun Mo</a>, 
        <a href="https://linsats.github.io/">Lin Shao</a>,
        <a href="https://cfcs.pku.edu.cn/baoquan/">Baoquan Chen</a>, 
        <a href="https://geometry.stanford.edu/member/guibas/index.html">Leonidas Guibas</a>, 
        <a href="https://zsdonghao.github.io/">Hao Dong</a>.
        <br>
            <em>NeurIPS</em>, 2020 <br>
            <a href="https://arxiv.org/abs/2006.07793">arXiv</a>
            / 
            <a href="https://github.com/Championchess/Generative-3D-Part-Assembly">codes</a>
            / 
            <a href="https://hyperplane-lab.github.io/Generative-3D-Part-Assembly/">project page</a>
            / 
            <a href="./QingnanFan_files/arxiv_2020_part_assembly.bib">bibtex</a>
            / 
            press (<a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650799676&idx=4&sn=1d2c6761bd3892686aacfc5d5dc1c14c&chksm=871a3a42b06db35402bc4e3ed6334f99b0e408ccf9ea30a072ec8bbd4d510e2a35887b563408&scene=0&xtrack=1&key=b21c8bfc2e98d5d832fabcf5a6128c64545a73289c8282c226af065f0e8e665138087c317b186eaebc3355bd9f2e7898b264453a14bd40dffbbb6fef2ef4abeec2a55a98cd3059f89720fff44355005b3bd6c07b912f9076963bed81b37c096beb0b826a868249f36912f97e3e7aaddf2db31632acfed190f0cc958aac41e3d8&ascene=1&uin=NDE4NjY0ODU1&devicetype=Windows+10+x64&version=6300002f&lang=zh_CN&exportkey=AWEFijHWuK4REu4n0VpJCOc%3D&pass_ticket=%2FxhWQurVrRrCi87xYVsAtep82meBarP1vauCZheyCMo17a9a4Hpo24ulX3EPdonG&wx_header=0">机器之心</a>,<a href="https://mp.weixin.qq.com/s?__biz=MzA5ODEzMjIyMA==&mid=2247547123&idx=4&sn=dea62a5edc7a65687d08872ce7ebb5ac&chksm=90943160a7e3b876a68ad4b69af47d5b57e40d50d5ba0034db79e2801dc6d6531eacee36e635&mpshare=1&scene=1&srcid=1017FVRyXZjpjkBieLaw7eQX&sharer_sharetime=1602869239113&sharer_shareid=49c5a30c6732bec1bffca4ce2cfd738b&key=905d9831417cd6b735a634c11fe9e11a86e7bec0fce71b3b6a37c07ef6c6049aea49aff5f0223327ab828a3657dbcd0fb4b9aad0c19b9ee4dedc401426ecd5fc0a44f846a5fb951c4039c3b26e3184934d8810e75e3a13d21762ae46ec85e060c0e769031a118bb4fcaf7d0d6d6c8944979019e20273ca05103f170d592abb78&ascene=1&uin=NDE4NjY0ODU1&devicetype=Windows+10+x64&version=6300002f&lang=zh_CN&exportkey=AYpfmqiYvoArYHlAv2MUXGs%3D&pass_ticket=%2FxhWQurVrRrCi87xYVsAtep82meBarP1vauCZheyCMo17a9a4Hpo24ulX3EPdonG&wx_header=0">AI科技评论</a>)
            <p></p>
            <p> A dynamic graph learning algorithm for autonomous part assembly. It learns to reason an assembly-oriented dynamically-evolved relation graph, which indicates the assembly process which is guided by the major parts (chair leg&seat).</p>
          </td>
        </tr>

          <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
            <td width="25%">
              <div class="one">
              <div class="two" id="portrait_image" style="opacity: 0;">
              <img src="./QingnanFan_files/tip20_thumbnailv3.png" width="175" alt="" style="border-style: none" align="middle">
              </div>
              <img src="./QingnanFan_files/tip20_thumbnailv3.png" width="175" alt="" style="border-style: none" align="middle">
              </div>
              <script type="text/javascript">
              function portrait_start() {
              document.getElementById('portrait_image').style.opacity = "1";
              }
              function portrait_stop() {
              document.getElementById('portrait_image').style.opacity = "0";
              }
              portrait_stop()
              </script>
            </td>
            <td valign="top" width="75%">
          <a href="./QingnanFan_files/tip-2020.pdf">
                  <papertitle>Controllable Image Processing via Adaptive FilterBank Pyramid</papertitle>
          </a>
          <br>
          <a href="http://www.dongdongchen.bid/">Dongdong Chen</a>, 
          <strong>Qingnan Fan</strong>,   
          <a href="https://liaojing.github.io/html/">Jing Liao</a>,
          <a href="https://angelicaiaviles.wordpress.com/">Angelica I. Aviles-Rivero</a>, 
          <a href="http://www.lyuan.org/">Lu Yuan</a>,
          <a href="http://staff.ustc.edu.cn/~ynh/">Nenghai Yu</a>, 
          <a href="https://www.microsoft.com/en-us/research/people/ganghua/">Gang Hua</a>.
          <br>
              <em>TIP</em>, 2020 <br>
              <a href="./QingnanFan_files/tip-2020.bib">bibtex</a>
              <p></p>
              <p> we propose a new plugin module, “Adaptive Filterbank Pyramid”, which can be inserted into a backbone network to support multiple operators and continuous parameter tuning.</p>
            </td>
          </tr>
          
    <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
      <td width="25%">
        <div class="one">
        <div class="two" id="portrait_image" style="opacity: 0;">
        <img src="./QingnanFan_files/iccv19_thumbnail_v3.png" width="175" alt="" style="border-style: none" align="middle">
        </div>
        <img src="./QingnanFan_files/iccv19_thumbnail_v3.png" width="175" alt="" style="border-style: none" align="middle">
        </div>
        <script type="text/javascript">
        function portrait_start() {
        document.getElementById('portrait_image').style.opacity = "1";
        }
        function portrait_stop() {
        document.getElementById('portrait_image').style.opacity = "0";
        }
        portrait_stop()
        </script>
      </td>
      <td valign="top" width="75%">
    <a href="./QingnanFan_files/iccv_2019.pdf">
            <papertitle>RainFlow: Optical Flow under Rain Streaks and Rain Veiling Effect</papertitle>
    </a>
    <br>    
    <a href="https://liruoteng.github.io/">Ruoteng Li</a>, 
    <a href="http://tanrobby.github.io/">Robby T. Tan</a>, 
    <a href="https://www.ece.nus.edu.sg/stfpage/eleclf/">Loong-Fah Cheong</a>,
    <a href="https://angelicaiaviles.wordpress.com/">Angelica I. Aviles-Rivero</a>, 
    <strong>Qingnan Fan</strong>, 
    <a href="http://www.damtp.cam.ac.uk/user/cbs31/Home.html">Carola-Bibiane Schönlieb</a>.
    <br>
        <em>ICCV</em>, 2019 <br>
        <a href="./QingnanFan_files/iccv_2019.bib">bibtex</a>
        <p></p>
        <p> A deep-learning based optical flow approach designed to handle heavy rain. </p>
      </td>
    </tr>

    <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
      <td width="25%">
        <div class="one">
        <div class="two" id="portrait_image" style="opacity: 0;">
        <img src="./QingnanFan_files/miccai2019_thumbnail.png" width="175" alt="" style="border-style: none" align="middle">
        </div>
        <img src="./QingnanFan_files/miccai2019_thumbnail.png" width="175" alt="" style="border-style: none" align="middle">
        </div>
        <script type="text/javascript">
        function portrait_start() {
        document.getElementById('portrait_image').style.opacity = "1";
        }
        function portrait_stop() {
        document.getElementById('portrait_image').style.opacity = "0";
        }
        portrait_stop()
        </script>
      </td>
      <td valign="top" width="75%">
    <!-- <papertitle>GraphX<sup>NET</sup> - Chest X-Ray Classification Under Extreme Minimal Supervision</papertitle> -->
    <a href="./QingnanFan_files/miccai_2019.pdf">
            <papertitle>GraphX<sup>NET</sup> - Chest X-Ray Classification Under Extreme Minimal Supervision</papertitle>
    </a>
    <br>
    <a href="https://angelicaiaviles.wordpress.com/">Angelica Aviles-Rivero</a>,
    <a href="https://www.math.u-bordeaux.fr/~npapadak/">Nicolas Papadakis</a>, 
    <a href="https://liruoteng.github.io/">Ruoteng Li</a>, 
    <a href="https://www.ccimi.maths.cam.ac.uk/members/profile/Philip%20Sellars/">Philip Sellars</a>, 
    <strong>Qingnan Fan</strong>, 
    <a href="https://tanrobby.github.io/">Robby Tan</a>,
    <a href="http://www.damtp.cam.ac.uk/user/cbs31/Home.html">Carola-Bibiane Schönlieb</a>.
    
    <br>
        <em>MICCAI</em>, 2019 <br>
        <a href="https://arxiv.org/abs/1907.10085">arXiv</a>
        / 
        <a href="./QingnanFan_files/miccai_2019.bib">bibtex</a>
        <p></p>
        <p> A novel semi-supervised framework for X-ray classification which is based on a graph-based optimisation model. A new multi-class classification functional that strengthens the synergy between the limited number of labels and the huge amount of unlabelled data. </p>
      </td>
    </tr>

    <tr onmouseout="tip19_stop()" onmouseover="tip19_start()">
      <td width="25%">
        <div class="one">
        <div class="two" id="tip19_thumbnail" style="opacity: 0;">
        <img src="./QingnanFan_files/tip19_thumbnail3.png" width="175" alt="" style="border-style: none" align="middle">
        </div>
        <img src="./QingnanFan_files/tip19_thumbnail3.png" width="175" alt="" style="border-style: none" align="middle">
        </div>
        <script type="text/javascript">
        function tip19_start() {
        document.getElementById('tip19_thumbnail').style.opacity = "1";
        }
        function tip19_stop() {
        document.getElementById('tip19_thumbnail').style.opacity = "0";
        }
        tip19_stop()
        </script>
      </td>
      <td valign="top" width="75%">
    <a href="./QingnanFan_files/tip_2019.pdf">
            <papertitle>Mirror, Mirror, on the Wall, Who's Got the Clearest Image of Them All? - A Tailored Approach to Single Image Reflection Removal</papertitle>
    </a>
    <br>
    <a href="https://danielheydecker.wordpress.com/">Daniel Heydecker*</a>, 
    <a href="http://www.damtp.cam.ac.uk/user/gam37/">Georg Maierhofer*</a>, 
    <a href="https://angelicaiaviles.wordpress.com/">Angelica Aviles-Rivero*</a>,
    <strong>Qingnan Fan</strong>, 
    <a href="http://www.dongdongchen.bid/">Dongdong Chen</a>,
    <a href="http://www.damtp.cam.ac.uk/user/cbs31/Home.html">Carola-Bibiane Schönlieb</a>,
    <a href="https://ivrl.epfl.ch/people/people-susstrunk/">Sabine Süsstrunk</a>.

    <br>
        <em>TIP</em>, 2019 <br>
        <a href="https://arxiv.org/abs/1805.11589">arXiv</a>
        / 
        <a href="./QingnanFan_files/tip_2019.bib">bibtex</a>
        <p></p>
        <p> A simple and tractable user interactive tool for single image reflection removal, which is facilitated with a spatially-aware prior term solved by an efficient half-quadratic splitting optimization approach. </p>
      </td>
    </tr>

    <tr onmouseout="wacv19_stop()" onmouseover="wacv19_start()">
      <td width="25%">
        <div class="one">
        <div class="two" id="wacv19_thumbnail" style="opacity: 0;">
          <img src="./QingnanFan_files/wacv19_thumbnail_before.png" width="175" alt="" style="border-style: none" align="middle">
        </div>
        <img src="./QingnanFan_files/wacv19_thumbnail_after.png" width="175" alt="" style="border-style: none" align="middle">
        </div>
        <script type="text/javascript">
        function wacv19_start() {
        document.getElementById('wacv19_thumbnail').style.opacity = "1";
        }
        function wacv19_stop() {
        document.getElementById('wacv19_thumbnail').style.opacity = "0";
        }
        wacv19_stop()
        </script>
      </td>
      <td valign="top" width="75%">
    <a href="./QingnanFan_files/wacv_2019.pdf">
            <papertitle>Gated Context Aggregation Network for Image Dehazing and Deraining</papertitle>
    </a>
    <!-- <papertitle>Image Smoothing via Unsupervised Learning</papertitle> -->
    <br>
    <a href="http://www.dongdongchen.bid/">Dongdong Chen</a>, 
    <a href="http://mingminghe.com/">Mingming He</a>, 
    <strong>Qingnan Fan</strong>, 
    <a href="https://liaojing.github.io/html/">Jing Liao</a>,
    <a href="https://scholar.google.com/citations?user=vUs1ptEAAAAJ&hl=en">Liheng Zhang</a>,
    <a href="http://home.ustc.edu.cn/~houdd/">Dongdong Hou</a>,
    <a href="http://www.lyuan.org/">Lu Yuan</a>,
    <a href="https://www.microsoft.com/en-us/research/people/ganghua/">Gang Hua</a>.

    <br>
        <em>WACV</em>, 2019 <br>
        <a href="https://arxiv.org/abs/1811.08747">arXiv</a>
        / 
        <a href="https://github.com/cddlyf/GCANet">codes</a>
        / 
        <a href="./QingnanFan_files/wacv_2019.bib">bibtex</a>
        <p></p>
        <p> A novel end-to-end gated context aggregation network GCANet that outperforms all the existing appraoches by a large margin on both image dehazing and deraining tasks.</p>
      </td>
    </tr>

    <tr onmouseout="siga18_stop()" onmouseover="siga18_start()">
      <td width="25%">
        <div class="one">
        <div class="two" id="siga18_thumbnail" style="opacity: 0;">
          <img src="./QingnanFan_files/siga18_thumbnail_before.png" width="175" alt="" style="border-style: none" align="middle">
        </div>
        <img src="./QingnanFan_files/siga18_thumbnail_after.png" width="175" alt="" style="border-style: none" align="middle">
        </div>
        <script type="text/javascript">
        function siga18_start() {
        document.getElementById('siga18_thumbnail').style.opacity = "1";
        }
        function siga18_stop() {
        document.getElementById('siga18_thumbnail').style.opacity = "0";
        }
        siga18_stop()
        </script>
      </td>
      <td valign="top" width="75%">
    <a href="./QingnanFan_files/siggraph_asia_2018.pdf">
            <papertitle>Image Smoothing via Unsupervised Learning</papertitle>
    </a>
    <!-- <papertitle>Image Smoothing via Unsupervised Learning</papertitle> -->
    <br>
        <strong>Qingnan Fan</strong>, 
        <a href="http://jlyang.org/">Jiaolong Yang</a>, 
        <a href="http://www.davidwipf.com/">David Wipf</a>,        
        <a href="http://www.cs.sdu.edu.cn/~baoquan/">Baoquan Chen</a>,
        <a href="https://www.microsoft.com/en-us/research/people/xtong/">Xin Tong</a>.
    <br>
        <em>SIGGRAPH Asia</em>, 2018 & <em>TOG</em>, 2018 <br>
        <a href="https://arxiv.org/abs/1811.02804">arXiv</a>
        / 
        <a href="https://github.com/fqnchina/ImageSmoothing">codes</a>
        / 
        <a href="https://www.dropbox.com/s/p3ql7etstto1g4e/siggraph_asia_2018_supp.pdf?dl=0">supp file</a>
        /
        <a href="./QingnanFan_files/siga_2018.bib">bibtex</a>
        <p></p>
        <p> Treat deep learning as an optimization tool to minimize the proposed image smoothing objective function in an unsupervised manner. Multiple different smoothing effects can be easily learned by adaptively changing the proposed objective function.</p>
      </td>
    </tr>

    <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
      <td width="25%">
        <div class="one">
        <div class="two" id="portrait_image" style="opacity: 0;">
          <img src="./QingnanFan_files/eccv18_thumbnail.png" width="175" alt="" style="border-style: none" align="middle">
        </div>
        <img src="./QingnanFan_files/eccv18_thumbnail.png" width="175" alt="" style="border-style: none" align="middle">
        </div>
        <script type="text/javascript">
        function portrait_start() {
        document.getElementById('portrait_image').style.opacity = "1";
        }
        function portrait_stop() {
        document.getElementById('portrait_image').style.opacity = "0";
        }
        portrait_stop()
        </script>
      </td>
      <td valign="top" width="75%">
    <a href="./QingnanFan_files/eccv_2018.pdf">
            <papertitle>Decouple Learning for Parameterized Image Operators</papertitle>
    </a>
    <br>
    <strong>Qingnan Fan*</strong>, 
    <a href="http://www.dongdongchen.bid/">Dongdong Chen*</a>, 
    <a href="http://www.lyuan.org/">Lu Yuan</a>,
    <a href="https://www.microsoft.com/en-us/research/people/ganghua/">Gang Hua</a>, 
    <a href="http://staff.ustc.edu.cn/~ynh/">Nenghai Yu</a>, 
    <a href="http://www.cs.sdu.edu.cn/~baoquan/">Baoquan Chen</a>.
    <br>
        <em>ECCV</em>, 2018 <br>
        <a href="https://arxiv.org/abs/1807.08186">arXiv</a>
        / 
        <a href="https://github.com/fqnchina/DecoupleLearning">codes</a>
        /
        <a href="./QingnanFan_files/eccv_2018_supp.pdf">supp file</a>
        /
        <a href="./QingnanFan_files/eccv_2018_poster.pdf">poster</a>
        /
        <a href="./QingnanFan_files/eccv_2018.bib">bibtex</a>
        <p></p>
        <p> The first decouple learning framework that is capable of successfully incorporating many different parameterized image operators into a single network without requirement of retraining or fintuning any other networks. </p>
      </td>
    </tr>

    <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
      <td width="25%">
        <div class="one">
        <div class="two" id="portrait_image" style="opacity: 0;">
          <img src="./QingnanFan_files/cvpr18_thumbnail.png" width="175" alt="" style="border-style: none" align="middle">
        </div>
        <img src="./QingnanFan_files/cvpr18_thumbnail.png" width="175" alt="" style="border-style: none" align="middle">
        </div>
        <script type="text/javascript">
        function portrait_start() {
        document.getElementById('portrait_image').style.opacity = "1";
        }
        function portrait_stop() {
        document.getElementById('portrait_image').style.opacity = "0";
        }
        portrait_stop()
        </script>
      </td>
      <td valign="top" width="75%">
      <a href="./QingnanFan_files/cvpr_2018.pdf">
            <papertitle>Revisiting Deep Intrinsic Image Decompositions</papertitle>
      </a>
      <br>
        <strong>Qingnan Fan</strong>, 
        <a href="http://jlyang.org/">Jiaolong Yang</a>, 
        <a href="https://www.microsoft.com/en-us/research/people/ganghua/">Gang Hua</a>, 
        <a href="http://www.cs.sdu.edu.cn/~baoquan/">Baoquan Chen</a>,
        <a href="http://www.davidwipf.com/">David Wipf</a>.

        <br>
        <em>CVPR</em>, 2018 <strong style="color:red">(Oral)</strong><br>
        <a href="https://arxiv.org/abs/1701.02965">arXiv</a>
        / 
        <a href="https://github.com/fqnchina/IntrinsicImage">codes</a>
        /
        <a href="./QingnanFan_files/cvpr_2018_v4_JL.pptx">slides</a>
        /  
        <a href="./QingnanFan_files/cvpr_2018_supp.pdf">supp file</a>
        /
        <a href="./QingnanFan_files/cvpr_2018_poster.pdf">poster</a>
        / 
        <a href="https://www.youtube.com/watch?v=LBJ20kxr1a0&t=3026s">presentation (start from 36:44)</a>
        /
        <a href="./QingnanFan_files/cvpr_2018.bib">bibtex</a>
        <p></p>
        <p>The first demonstration of a single basic deep architecture capable of achieving state-of-the-art results when applied to each of the major intrinsic benchmarks. </p>
      </td>
    </tr>

     <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
      <td width="25%">
        <div class="one">
        <div class="two" id="portrait_image" style="opacity: 0;">
          <img src="./QingnanFan_files/iccv17_thumbnail.png" width="175" alt="" style="border-style: none" align="middle">
        </div>
        <img src="./QingnanFan_files/iccv17_thumbnail.png" width="175" alt="" style="border-style: none" align="middle">
        </div>
        <script type="text/javascript">
        function portrait_start() {
        document.getElementById('portrait_image').style.opacity = "1";
        }
        function portrait_stop() {
        document.getElementById('portrait_image').style.opacity = "0";
        }
        portrait_stop()
        </script>
      </td>
      <td valign="top" width="75%">
      <a href="./QingnanFan_files/iccv_2017.pdf">
            <papertitle>A Generic Deep Architecture for Single Image Reflection Removal and Image Smoothing</papertitle>
      </a>
      <br>
        <strong>Qingnan Fan</strong>, 
        <a href="http://jlyang.org/">Jiaolong Yang</a>, 
        <a href="https://www.microsoft.com/en-us/research/people/ganghua/">Gang Hua</a>, 
        <a href="http://www.cs.sdu.edu.cn/~baoquan/">Baoquan Chen</a>,
        <a href="http://www.davidwipf.com/">David Wipf</a>.

        <br>
        <em>ICCV</em>, 2017 <br>
        <a href="https://arxiv.org/abs/1708.03474">arXiv</a>
        / 
        <a href="https://github.com/fqnchina/CEILNet">codes</a>
        / 
        <a href="./QingnanFan_files/iccv_2017_supp.pdf">supp file</a>
        / 
        <a href="./QingnanFan_files/iccv_2017_poster.pdf">poster</a>
        / 
        <a href="./QingnanFan_files/iccv_2017.bib">bibtex</a>
        <p></p>
        <p>An advanced deep architecture for low-level vision tasks; A novel reflection image synthesis approach which enables outstanding generalization ability to real images with trained newtork. </p>
      </td>
    </tr>

    <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
      <td width="25%">
        <div class="one">
        <div class="two" id="portrait_image" style="opacity: 0;">
        <img src="./QingnanFan_files/siga_2015.gif" width="175" alt="" style="border-style: none" align="middle">
        </div>
        <img src="./QingnanFan_files/siga_2015.gif" width="175" alt="" style="border-style: none" align="middle">
        </div>
        <script type="text/javascript">
        function portrait_start() {
        document.getElementById('portrait_image').style.opacity = "1";
        }
        function portrait_stop() {
        document.getElementById('portrait_image').style.opacity = "0";
        }
        portrait_stop()
        </script>
      </td>
      <td valign="top" width="75%">
      <a href="https://www.dropbox.com/s/q2xvrag0g5l8wii/%5B2015%5D%5Bsiggraph_asia%5DJumpCut%20Non-Successive%20Mask%20Transfer%20and%20Interpolation%20for%20Video%20Cutout.pdf?dl=0">
            <papertitle>JumpCut: Non-Successive Mask Transfer and Interpolation for Video Cutout</papertitle>
      </a>
      <br>
            <strong>Qingnan Fan</strong>,
            <a href="http://vr.sdu.edu.cn/~zf/">Fan Zhong</a>,
            <a href="http://www.cs.huji.ac.il/~danix/">Dani Lischinski</a>,
            <a href="http://www.math.tau.ac.il/~dcor/">Daniel Cohen-Or</a>,
            <a href="http://www.cs.sdu.edu.cn/~baoquan/">Baoquan Chen</a>.
        <br>
        <em>SIGGRAPH Asia</em>, 2015 & <em>TOG</em>, 2015 <br>
        <a href="https://github.com/sduirc/JumpCut">codes</a>
        / 
        <a href="https://www.dropbox.com/scl/fi/jr84cmwryf50vnb61wb6e/siga_2015.pptx?dl=0&rlkey=9jn17dt75d0g2bi23wlax5hb6">slides</a>
        / 
        <a href="https://www.youtube.com/watch?v=drqnwDg0JFM&t=77s">video</a>
        / 
        <a href="https://www.dropbox.com/s/4b76crsifryn6rq/siga_2015_supp.rar?dl=0">supp file</a>
        / 
        <a href="https://www.dropbox.com/s/v0v3pkrhz1vizyt/VideoSeg_dataset.rar?dl=0">dataset</a>
        / 
        <a href="./QingnanFan_files/siga_2015.bib">bibtex</a>
        <!-- /
        <a href="http://irc.cs.sdu.edu.cn/JumpCut/">deprecated project page</a> -->
        <p></p>
        <p>An interactive real-time video segmentation algorithm. Significantly improve the video cutout accuracy and efficiency.</p>
      </td>
    </tr>

    <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
      <td width="25%">
        <div class="one">
        <div class="two" id="portrait_image" style="opacity: 0;">
        <img src="./QingnanFan_files//a97-lu.gif" width="110" alt="" style="border-style: none" align="right">
        </div>
        <img src="./QingnanFan_files//a97-lu.gif" width="110" alt="" style="border-style: none" align="right">
        </div>
        <script type="text/javascript">
        function portrait_start() {
        document.getElementById('portrait_image').style.opacity = "1";
        }
        function portrait_stop() {
        document.getElementById('portrait_image').style.opacity = "0";
        }
        portrait_stop()
        </script>
      </td>
      <td valign="top" width="75%">
      <a href="https://www.dropbox.com/s/f84dqmtht41k8vv/a97-lu.pdf?dl=0">
            <papertitle>Build-to-Last: Strength to Weight 3D Printed Objects</papertitle>
      </a>
      <br>
            <a href="http://vr.sdu.edu.cn/~lulin/">Lin Lu</a>,
            <a href="http://www.cs.bgu.ac.il/~asharf/">Andrei Sharf</a>,
            Haisen Zhao, Yuan Wei,
            <strong>Qingnan Fan</strong>, Xuelin Chen,
            <a href="http://www.animlife.com/">Yann Savoye</a>,
            <a href="http://www.cs.sdu.edu.cn/zh/60">Changhe Tu</a>,
            <a href="http://www.math.tau.ac.il/~dcor/">Daniel Cohen-Or</a>,
            <a href="http://www.cs.sdu.edu.cn/~baoquan/">Baoquan Chen</a>.
        <br>
        <em>SIGGRAPH</em>, 2014 & <em>TOG</em>, 2014 <br>
        <a href="https://www.youtube.com/watch?v=V5IrPSvcm_8&t=5s">video</a>
        / 
        <a href="./QingnanFan_files/sig_2014.bib">bibtex</a>
        <p></p>
        <p>Reduce the material cost and weight of a given object while providing a durable printed model that is resistant to impact and external forces.</p>
      </td>
    </tr>

  </tbody></table>

    
    <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
        <td width="100%" valign="middle">
          <heading>Preprints</heading>
        </td>
      </tr>
      </tbody></table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

    <tbody>
      <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
        <td width="25%">
          <div class="one">
          <div class="two" id="portrait_image" style="opacity: 0;"><img src="./QingnanFan_files/arxiv20-reflection-outputv2.png"></div>
          <img src="./QingnanFan_files/arxiv20-reflection-inputv2.png">
          </div>
          <script type="text/javascript">
          function portrait_start() {
          document.getElementById('portrait_image').style.opacity = "1";
          }
          function portrait_stop() {
          document.getElementById('portrait_image').style.opacity = "0";
          }
          portrait_stop()
          </script>
        </td>
        <td valign="top" width="75%">
      <a href="./QingnanFan_files/arxiv_2020_reflection.pdf">
              <papertitle>Deep Reflection Prior</papertitle>
      </a>
      <br>
      Yingda Yin*,
      <strong>Qingnan Fan*</strong>, 
      <a href="http://www.dongdongchen.bid/">Dongdong Chen</a>, 
      Yujie Wang,
      <a href="https://angelicaiaviles.wordpress.com/">Angelica I. Aviles-Rivero</a>, 
      <a href="https://liruoteng.github.io/">Ruoteng Li</a>, 
      <a href="http://www.damtp.cam.ac.uk/user/cbs31/Home.html">Carola-Bibiane Schönlieb</a>,
      <a href="http://www.cs.huji.ac.il/~danix/">Dani Lischinski</a>, 
      <a href="https://cfcs.pku.edu.cn/baoquan/">Baoquan Chen</a>.
      <br>
          <em>arXiv</em>, 2020 <br>
          <a href="https://arxiv.org/abs/1912.03623">arXiv</a>
          / 
          <a href="./QingnanFan_files/arxiv_2020_reflection.bib">bibtex</a>
          <p></p>
          <p> We propose a single-image reflection removal algorithm by learning from multi-image prior during training without direct supervision on the ground truth clean background. </p>
        </td>
      </tr>

  </tbody></table> -->
  

</body></html>